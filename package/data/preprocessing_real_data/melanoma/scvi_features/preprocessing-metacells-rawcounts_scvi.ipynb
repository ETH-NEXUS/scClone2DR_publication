{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46b9b619",
   "metadata": {},
   "source": [
    "# Saving final dataframe with all the information regarding the clusters (ID, label and category $\\in \\{ healthy, tumor\\}$) WITH RAW COUNTS (to be used later for scvi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e25f1564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "all_clonelabels = ['healthy','tumor']\n",
    "\n",
    "gene_set_collections = np.array(['c6','hallmarks', 'c2_pid', 'gene','geneOncoKB'])\n",
    "gene_set_collection = gene_set_collections[4]\n",
    "\n",
    "clonemodes = np.array(['scatrex','phenograph'])\n",
    "clonemode = clonemodes[0]\n",
    "path_scatrex = '/data/users/04_share_reanalysis_results/melanoma_2025/new_scatrex/'\n",
    "pathgsva = '/data/users/04_share_reanalysis_results/02_melanoma/04_metacells_gsva/{0}/'.format('gene' if ('gene' in gene_set_collection) else gene_set_collection)\n",
    "path_MC = '/data/users/04_share_reanalysis_results/02_melanoma/03_metacells_atypical_removed/'\n",
    "pathsave = '/data/users/04_share_reanalysis_results/melanoma_2025/02_atypical_removed_preprocessing/metacells_{0}_{1}_rawcounts/'.format(gene_set_collection, clonemode)\n",
    "path_info_cohort = '/data/users/melanoma_sample.txt'\n",
    "\n",
    "\n",
    "\n",
    "def find_idx(string, array):\n",
    "    i = 0\n",
    "    while not(string in array[i]):\n",
    "        i += 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67387b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_TUMOR = 'Melanoma'\n",
    "def celltype2tumor(celltype):\n",
    "    return (KEY_TUMOR in celltype)\n",
    "\n",
    "def celltype2category(celltype):\n",
    "    if celltype2tumor(celltype):\n",
    "        return 'tumor'\n",
    "    else:\n",
    "        return 'healthy'\n",
    "        \n",
    "def label2category(label):\n",
    "    if label=='healthy':\n",
    "        return 'healthy'\n",
    "    else:\n",
    "        return 'tumor'\n",
    "    \n",
    "def celltype2label(celltype):\n",
    "    if KEY_TUMOR in celltype:\n",
    "        return 'tumor'\n",
    "    else:\n",
    "        return 'healthy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2ff7a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_reorder(data, data_cellIDs, ref_cellIDs):\n",
    "    dfmod = pd.DataFrame(data.reshape(1,-1), columns=data_cellIDs)\n",
    "    dfmod = dfmod[ref_cellIDs]\n",
    "    mod = dfmod.to_numpy().reshape(-1)\n",
    "    return mod\n",
    "\n",
    "def get_sample_names(use_scatrex_clone=False, gene_feature=False):\n",
    "    \"\"\"\n",
    "    Get the list of the name of samples that will be considered for the analysis.\n",
    "    We take the intersection of the samples for which required data is available (GSVA, SCATrEX clones, ...),\n",
    "    and we remove some problematic samples.\n",
    "    \"\"\"\n",
    "    samples_names = os.listdir(path_MC)\n",
    "    samples_names = np.unique([sample[:sample.find('_')] for sample in samples_names if 'h5' in sample])\n",
    "    if not(gene_feature):\n",
    "        samples_gsva = os.listdir(pathgsva)\n",
    "        samples_gsva = [sample[:sample.find('_')] for sample in samples_gsva]\n",
    "        samples_names = np.intersect1d(samples_names, samples_gsva)\n",
    "    if use_scatrex_clone:\n",
    "        samples_scatrex = os.listdir(path_scatrex)\n",
    "        samples_scatrex = [sample[:sample.find('_')] for sample in samples_scatrex]\n",
    "        samples_names = np.intersect1d(samples_names, samples_scatrex)\n",
    "    \n",
    "\n",
    "    # Load name of samples that should be removed (data not reliable)\n",
    "    dfsamples = pd.read_csv(path_info_cohort, sep=\"\\t\")\n",
    "    samples_removed = dfsamples.loc[dfsamples['part_cohort_analyses']==False]['sampleID'].to_numpy()\n",
    "    for i,sample in enumerate(samples_removed):\n",
    "        samples_removed[i] = sample\n",
    "\n",
    "    # Remove the sample that is an outlier (too many cells)\n",
    "    sample_names = [sample for sample in samples_names if sample!='MATIWAQ-T']\n",
    "    # Remove the other samples identified as not reliable\n",
    "    sample_names = [sample for sample in sample_names if not(sample in samples_removed)]\n",
    "\n",
    "\n",
    "    dfinfo = pd.read_csv(path_info_cohort, sep='\\t')\n",
    "    dfinfo = dfinfo[dfinfo['sampleID'].apply(lambda x: x in sample_names).values]\n",
    "    dfinfo = dfinfo.set_index('sampleID')\n",
    "    print('Total number of samples: ', len(sample_names))\n",
    "    return sample_names\n",
    "\n",
    "def get_scatrex_clone(sample, cellsIDs_rna):\n",
    "    \"\"\"\n",
    "    Get the clone IDs from SCATrEX. Note that SCATrEX is only run on tumor cells and thus we assign the label 0\n",
    "    to the non-malignant cells (and we make sure the SCATrEX subclones do not also have the label 0).\n",
    "    \"\"\"\n",
    "    filename = os.path.join(path_scatrex, \"{0}__scatrex.h5ad\".format(sample))\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        subclones = f['obs']['scatrex_obs_node']['codes'][()]\n",
    "        cellnames = f['obs']['cell_names'][:]\n",
    "        cellnames = np.array([cname.decode(\"utf-8\") for cname in cellnames])\n",
    "\n",
    "    # Loading the mapping from single cells to SEAcells\n",
    "    data = pd.read_csv (os.path.join(path_MC,\"{0}.genes_cells_filtered_seacells_hard_assignment.tsv\".format(sample)), sep = '\\t')\n",
    "    seacells = np.unique(data['SEACell'])\n",
    "    seacellnames = data['SEACell'].to_numpy()\n",
    "    nbcellsfound = 0\n",
    "    seacell2subclone = {}\n",
    "    for seacell in seacells:\n",
    "        seacell2subclone[seacell] = 0\n",
    "        idxcell = np.where(seacellnames==seacell)[0][0]\n",
    "        #seacelltype = seacelltypes[idxcell]\n",
    "        df = data[data['SEACell']==seacell]\n",
    "        for cellID in df['archetype_barcode'].values:\n",
    "            idxs = np.where(cellnames==cellID)[0]\n",
    "            if (len(idxs))>=1:\n",
    "                nbcellsfound += len(idxs)\n",
    "                # +1 since only tumor SEAcell have been used in SCATrEX and 0 is for the non malignant cells\n",
    "                seacell2subclone[seacell] = list(subclones[idxs])[0]+1\n",
    "    return {cell: subcloneID for cell, subcloneID in seacell2subclone.items() if cell in cellsIDs_rna}\n",
    "    \n",
    "    \n",
    "def get_cellIDs(sample, use_scatrex_clone=False):\n",
    "    \"\"\"\n",
    "    Get the set of MetaCells that we can consider for the analysis. Indeed, if we use SCATrEX subclones,\n",
    "    SCATrEX has a pre-filtering step that remove some part of the tumor cells (and therefore we need to get rid of them).\n",
    "    \"\"\"\n",
    "    filename = os.path.join(path_MC, \"{0}_seacells.atypical_removed.h5\".format(sample))\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        cellnames = f['cell_attrs']['cell_names'][:]\n",
    "        cellnames = np.array([cname.decode(\"utf-8\") for cname in cellnames])\n",
    "        seacelltypes = np.array([el.decode(\"utf-8\") for el in f['cell_attrs']['celltype_final'][:]])\n",
    "    if use_scatrex_clone:\n",
    "        filename = os.path.join(path_scatrex, \"{0}__scatrex.h5ad\".format(sample))\n",
    "        with h5py.File(filename, \"r\") as f:\n",
    "            cellnames_scatrex = f['obs']['cell_names'][:]\n",
    "            cellnames_scatrex = np.array([cname.decode(\"utf-8\") for cname in cellnames_scatrex])\n",
    "        cellnames_inter = []\n",
    "        for i, seatype in enumerate(seacelltypes):\n",
    "            if not(KEY_TUMOR in seatype): # SCATrEX is run only on Melanoma cells\n",
    "                cellnames_inter.append(cellnames[i])\n",
    "            else: # SCATrEX has considered only some of the tumor cells (filtering step)\n",
    "                if cellnames[i] in cellnames_scatrex:\n",
    "                    cellnames_inter.append(cellnames[i])\n",
    "    else:\n",
    "        return cellnames\n",
    "\n",
    "def get_selected_genes(sample_names, gene_set_collection):\n",
    "    \"\"\"\n",
    "    Return the set of features (genes) that will be used for the analysis.\n",
    "    \"\"\"\n",
    "    df = None\n",
    "#     for idsample, sample in tqdm(enumerate(sample_names)):\n",
    "#         filename = os.path.join(path_MC, \"{0}_seacells.atypical_removed.h5\".format(sample))\n",
    "\n",
    "#         with h5py.File(filename, \"r\") as f:\n",
    "#             res_var = f['gene_attrs']['residual_variance'][:]\n",
    "#             gene_ids = f['gene_attrs']['gene_ids'][:]\n",
    "#             gene_ids = np.array([gene_id.decode(\"utf-8\") for gene_id in gene_ids])\n",
    "#             if df is None:\n",
    "#                 df = pd.DataFrame({gene_id:[res_var[i]] for i, gene_id in enumerate(gene_ids)})\n",
    "#             else:\n",
    "#                 df_temp = pd.DataFrame({gene_id:[res_var[i]] for i, gene_id in enumerate(gene_ids)})\n",
    "#                 df = pd.concat([df, df_temp], ignore_index=True)\n",
    "#     # Drop columns where more than 50% of values are NaN\n",
    "#     df_cleaned = df.dropna(axis=1, thresh=len(df) * 0.1)\n",
    "#     means_res_var = df_cleaned.mean(axis=0, skipna=True)\n",
    "#     idxs = np.flip(np.argsort(means_res_var))\n",
    "#     selected_genes = df_cleaned.columns[idxs[:500]]\n",
    "\n",
    "    # Initialize an empty dictionary to store the largest residual variance per gene\n",
    "    if gene_set_collection==\"geneOncoKB\":\n",
    "        \n",
    "        # Extracting the ENSG codes of all genes in the OncoKB Cancer Gene List\n",
    "        from pyensembl.shell import collect_all_installed_ensembl_releases\n",
    "        from pyensembl import EnsemblRelease\n",
    "        #!pyensembl install --release 104 --species homo_sapiens\n",
    "        collect_all_installed_ensembl_releases()\n",
    "        genome = EnsemblRelease(release=104, species='homo_sapiens')\n",
    "        data=pd.read_csv('../cancerGeneList.tsv',sep='\\t')\n",
    "        gene_names = data['Hugo Symbol'].unique()\n",
    "        gene_ids = []\n",
    "        for gene_name in gene_names:\n",
    "            try:\n",
    "                gene_ids.append(genome.gene_ids_of_gene_name(gene_name))\n",
    "            except:\n",
    "                print(gene_name)\n",
    "        gene_idsOnco = np.array(gene_ids).reshape(-1)\n",
    "        \n",
    "        # Counting for each gene the number of samples for which we have data\n",
    "        all_gene_ids = []\n",
    "        dic_all_gene_ids = {}\n",
    "        for idsample, sample in tqdm(enumerate(sample_names)):\n",
    "            filename = os.path.join(path_MC, f\"{sample}_seacells.atypical_removed.h5\")\n",
    "\n",
    "            with h5py.File(filename, \"r\") as f:\n",
    "                res_var = f['gene_attrs']['residual_variance'][:]\n",
    "                gene_ids = f['gene_attrs']['gene_ids'][:]\n",
    "                gene_ids = np.array([gene_id.decode(\"utf-8\") for gene_id in gene_ids])\n",
    "                all_gene_ids = list(set(list(set(gene_ids))+list(set(all_gene_ids))))\n",
    "                for gene in gene_ids:\n",
    "                    dic_all_gene_ids[gene] = dic_all_gene_ids.get(gene, 0) + 1\n",
    "\n",
    "        # Defining the final gene set considered\n",
    "        selected_genes = []\n",
    "        threshold = int(0.95*len(sample_names))\n",
    "        for gene in gene_idsOnco:\n",
    "            if (gene in (all_gene_ids)):\n",
    "                if dic_all_gene_ids[gene]>=threshold:\n",
    "                    selected_genes.append(gene)\n",
    "        \n",
    "    else:\n",
    "        gene_variance_dict = {}\n",
    "\n",
    "        for idsample, sample in tqdm(enumerate(sample_names)):\n",
    "            filename = os.path.join(path_MC, f\"{sample}_seacells.atypical_removed.h5\")\n",
    "\n",
    "            with h5py.File(filename, \"r\") as f:\n",
    "                res_var = f['gene_attrs']['residual_variance'][:]\n",
    "                gene_ids = f['gene_attrs']['gene_ids'][:]\n",
    "                gene_ids = np.array([gene_id.decode(\"utf-8\") for gene_id in gene_ids])\n",
    "\n",
    "                for gene_id, var in zip(gene_ids, res_var):\n",
    "                    if gene_id not in gene_variance_dict or var > gene_variance_dict[gene_id]:\n",
    "                        gene_variance_dict[gene_id] = var\n",
    "\n",
    "        # Convert the dictionary to a DataFrame\n",
    "        df = pd.DataFrame(list(gene_variance_dict.items()), columns=['Gene', 'Max_Residual_Variance'])\n",
    "\n",
    "        # Sort genes by maximum residual variance\n",
    "        selected_genes = np.array(df.nlargest(500, 'Max_Residual_Variance')['Gene'])\n",
    "    return selected_genes\n",
    "\n",
    "def get_feat_celltype_genefeat(sample, cellsIDs, selected_genes):\n",
    "    \"\"\"\n",
    "    Return the feature matrix and the celltypes when working with genes as features.\n",
    "    \"\"\"\n",
    "    df = None\n",
    "    filename = os.path.join(path_MC, \"{0}_seacells.atypical_removed.h5\".format(sample))\n",
    "\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        X = f['raw_counts'][:]\n",
    "        cell_names = f['cell_attrs']['cell_names'][:]\n",
    "        gene_ids = f['gene_attrs']['gene_ids'][:]\n",
    "        cell_names = np.array([cname.decode(\"utf-8\") for cname in cell_names])\n",
    "        gene_ids = np.array([gene_id.decode(\"utf-8\") for gene_id in gene_ids])\n",
    "        seacelltypes = f['cell_attrs']['celltype_final'][()]\n",
    "        seacelltypes = np.array([el.decode(\"utf-8\") for el in f['cell_attrs']['celltype_final'][:]])\n",
    "\n",
    "    \n",
    "    dfsample = pd.DataFrame(X, columns=gene_ids)\n",
    "    dfsample.set_index(cell_names, inplace=True)\n",
    "    dfsample = dfsample.loc[cellsIDs].reindex(columns=selected_genes) \n",
    "    dfcelltypes = pd.DataFrame(seacelltypes.reshape(1,-1), columns=cell_names)\n",
    "    dfcelltypes = dfcelltypes[cellsIDs]\n",
    "    return dfsample.to_numpy(), dfcelltypes.to_numpy().reshape(-1)\n",
    "    \n",
    "    \n",
    "def save_data(sample_names, gene_set_collection, use_scatrex_clone=False):\n",
    "    \"\"\"\n",
    "    Save the data file for each sample.\n",
    "    \"\"\"\n",
    "    print('Step 1/3: computing set of features')\n",
    "    gene_feature = 'gene' in gene_set_collection\n",
    "    if gene_feature:\n",
    "        selected_genes = get_selected_genes(sample_names, gene_set_collection)\n",
    "        feature_names = selected_genes\n",
    "    else:\n",
    "        set_pathways = []\n",
    "        for sample in sample_names:\n",
    "            df_gsva = pd.read_csv(os.path.join(pathgsva, '{0}_seacells_celltype_GSVA.tsv'.format(sample)), sep='\\t')\n",
    "            if len(set_pathways)==0:\n",
    "                set_pathways = df_gsva['gene_set'].to_numpy()\n",
    "            else:\n",
    "                set_pathways = np.union1d(set_pathways, df_gsva['gene_set'].to_numpy())\n",
    "        pathway2index = {pathway:i for i, pathway in enumerate(set_pathways)}\n",
    "        feature_names = set_pathways\n",
    "    \n",
    "    print('Step 2/3: preprocessing data for each sample')\n",
    "    for id_sample, sample in tqdm(enumerate(sample_names)):\n",
    "        cellsIDs_rna = get_cellIDs(sample)\n",
    "        if use_scatrex_clone:\n",
    "            seacell2subclone = get_scatrex_clone(sample, cellsIDs_rna)\n",
    "            clustersini = []\n",
    "            for seacellID in cellsIDs_rna:\n",
    "                clustersini.append(int(seacell2subclone[seacellID]))\n",
    "            clustersini = np.array(clustersini)\n",
    "        else:\n",
    "            with h5py.File(os.path.join(path_MC, '{0}_seacells.atypical_removed.h5'.format(sample)), 'r') as f:\n",
    "                cell_names = f['cell_attrs']['cell_names'][:]\n",
    "                cell_names = np.array([cname.decode(\"utf-8\") for cname in cell_names])\n",
    "                clustersini = np.array(f['cell_attrs'][\"phenograph_clusters\"][:]).astype(int)\n",
    "                clustersini = filter_reorder(clustersini, cell_names, cellsIDs_rna)\n",
    "\n",
    "        if gene_feature:\n",
    "            features, celltypes = get_feat_celltype_genefeat(sample, cellsIDs_rna, selected_genes)\n",
    "        else:\n",
    "            with h5py.File(os.path.join(path_MC, '{0}_seacells.atypical_removed.h5'.format(sample)), 'r') as f:\n",
    "                cell_names = f['cell_attrs']['cell_names'][:]\n",
    "                cell_names = np.array([cname.decode(\"utf-8\") for cname in cell_names])\n",
    "                celltypes = np.array([el.decode(\"utf-8\") for el in f['cell_attrs']['celltype_final'][:]])\n",
    "                celltypes = filter_reorder(celltypes, cell_names, cellsIDs_rna)\n",
    "            \n",
    "            df_gsva = pd.read_csv(os.path.join(pathgsva, '{0}_seacells_celltype_GSVA.tsv'.format(sample)), sep='\\t')\n",
    "            features = np.zeros((len(cellsIDs_rna), len(set_pathways)))\n",
    "            for idx_cell, cellID in enumerate(cellsIDs_rna):\n",
    "                df_gsva_cell = df_gsva[df_gsva['barcode']==cellID]\n",
    "                gene_sets = np.unique(df_gsva_cell['gene_set'].to_numpy())\n",
    "                missing_pathways = list(filter(lambda x: x not in gene_sets, set_pathways))\n",
    "                missing_barcode = [cellID for l in range(len(missing_pathways))]\n",
    "                missing_value = [0 for l in range(len(missing_pathways))]\n",
    "                df_missing = pd.DataFrame({'gene_set':missing_pathways, \n",
    "                                           'barcode': missing_barcode,\n",
    "                                           'value': missing_value\n",
    "                                          })\n",
    "                df_gsva_cell = pd.concat([df_gsva_cell, df_missing], axis=0)\n",
    "                df_gsva_cell = df_gsva_cell.set_index('gene_set')\n",
    "                df_gsva_cell = df_gsva_cell.sort_index(key=lambda x: x.map(pathway2index))\n",
    "                features[idx_cell,:] = df_gsva_cell['value'].to_numpy()\n",
    "    \n",
    "        data = np.array(cellsIDs_rna)\n",
    "        data = np.concatenate((data[:,None], features), axis=1)\n",
    "        data = np.concatenate((data, celltypes[:,None]), axis=1)\n",
    "        cellcategories = np.array([celltype2category(celltype) for celltype in celltypes])\n",
    "        data = np.concatenate((data, cellcategories[:,None]), axis=1)\n",
    "        data = np.concatenate((data, clustersini[:,None]), axis=1)\n",
    "\n",
    "        colnames = ['cell_id'] + ['dim_{0}_{1}'.format(i+1,gene_set) for i,gene_set in enumerate(feature_names)]\n",
    "        colnames += ['celltype', 'cellcategory', 'initial_cloneID']\n",
    "        df = pd.DataFrame(data, columns=colnames)\n",
    "        df = df.set_index('cell_id') \n",
    "\n",
    "        temp_df = df[['initial_cloneID','celltype']].groupby(['initial_cloneID','celltype']).size()\n",
    "        all_cloneIDs = np.unique(temp_df.index.get_level_values('initial_cloneID').values)\n",
    "        \n",
    "        if not(use_scatrex_clone):\n",
    "            cloneID2clonetype = {}\n",
    "            if False: # take the dominant celltype\n",
    "                for cloneID in all_cloneIDs:\n",
    "                    cloneID2clonetype[cloneID] = temp_df.loc[cloneID].idxmax()\n",
    "            else:\n",
    "                for cloneID in all_cloneIDs:\n",
    "                    # Get the subset for the current cloneID\n",
    "                    clone_counts = temp_df.loc[cloneID]\n",
    "\n",
    "                    # Separate into two groups\n",
    "                    melanoma_group = clone_counts[clone_counts.index.str.contains(KEY_TUMOR, case=False, na=False)]\n",
    "                    other_group = clone_counts[~clone_counts.index.str.contains(KEY_TUMOR, case=False, na=False)]\n",
    "\n",
    "                    # Sum the counts in each group\n",
    "                    melanoma_count = melanoma_group.sum() if not melanoma_group.empty else 0\n",
    "                    other_count = other_group.sum() if not other_group.empty else 0\n",
    "\n",
    "                    # Determine the assigned cell type\n",
    "                    if melanoma_count > other_count:\n",
    "                        cloneID2clonetype[cloneID] = KEY_TUMOR\n",
    "                    else:\n",
    "                        cloneID2clonetype[cloneID] = other_group.idxmax() if not other_group.empty else 'Unknown'\n",
    "        else:\n",
    "            cloneID2clonetype = {cloneID:KEY_TUMOR for cloneID in all_cloneIDs}\n",
    "            cloneID2clonetype[0] = 'non malignant'\n",
    "        clonetype_of_cells = [cloneID2clonetype[cloneID] for cloneID in (df['initial_cloneID'].values.copy())]\n",
    "        inicloneID2cluster = {inicloneID:i for i, inicloneID in enumerate(np.unique(df['initial_cloneID'].values))}\n",
    "        df_c = pd.DataFrame({\n",
    "                            'cell_id': cellsIDs_rna,\n",
    "                            'clonetype': clonetype_of_cells,\n",
    "                            'clonelabel': [celltype2label(clonetype) for clonetype in clonetype_of_cells],\n",
    "                             'clonecategory': [celltype2category(clonetype) for clonetype in clonetype_of_cells],\n",
    "                             'cloneID': [inicloneID2cluster[inicloneID] for inicloneID in df['initial_cloneID'].values]\n",
    "                            })\n",
    "        df_c = df_c.set_index('cell_id') \n",
    "        df = pd.concat([df, df_c], axis=1)\n",
    "\n",
    "        if (not(use_scatrex_clone) and id_sample==0):\n",
    "            # just a sanity check: The way I compute the celltype with the largest number of cells in each cluster should match the \n",
    "            # major celltypes in each cluster provided by Anne and Franziska\n",
    "            df_clusters_data = pd.read_csv(os.path.join(path_MC,'{0}_seacells.atypical_removed.phenograph_celltype_association.txt'.format(sample)), sep='\\t')\n",
    "            print(df_clusters_data)\n",
    "            df_clusters_data = df_clusters_data.set_index('Cluster')\n",
    "            print(df_clusters_data.index)\n",
    "            for cloneID in np.unique(df['initial_cloneID'].values):\n",
    "                print(cloneID, ' ', cloneID2clonetype[cloneID], ' ', df_clusters_data.loc[str(cloneID),]['Dominant.celltype'])\n",
    "        df.to_csv(os.path.join(pathsave,'sample2data/{0}.csv'.format(sample)), index=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0aa1f0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(sample_names, gene_set_collection, use_scatrex_clone=False):\n",
    "    \"\"\"\n",
    "    Main function to preprocess data.\n",
    "    \"\"\"\n",
    "    gene_feature = ('gene' in gene_set_collection)\n",
    "    save_data(sample_names, gene_set_collection, use_scatrex_clone=use_scatrex_clone)\n",
    "    # Find the max number of clusters within each labels across all samples\n",
    "    clonelabel2max_nb_cluster = {label: 0 for label in all_clonelabels}\n",
    "    for id_sample, sample in enumerate(tqdm(sample_names)):\n",
    "        df = pd.read_csv(pathsave+'sample2data/{0}.csv'.format(sample), index_col=0)\n",
    "        for label in all_clonelabels:\n",
    "            sample_nb_clusters_with_label = len(np.unique(df[df['clonelabel']==label]['cloneID']))\n",
    "            clonelabel2max_nb_cluster[label] = max([clonelabel2max_nb_cluster[label], sample_nb_clusters_with_label])    \n",
    "    print(clonelabel2max_nb_cluster)\n",
    "    print('Step 3/3: grouping cloneIDs by label and saving the clone_infos file')\n",
    "    sample2cloneID2clonetype = {}\n",
    "    for id_sample, sample in enumerate(tqdm(sample_names)):\n",
    "        sample2cloneID2clonetype[sample] = {}\n",
    "        df = pd.read_csv(pathsave+'sample2data/{0}.csv'.format(sample), index_col=0)\n",
    "        start_cloneID = 0 \n",
    "        for label in all_clonelabels:\n",
    "            df_label = (df[df['clonelabel']==label]).copy()\n",
    "            oldcloneIDs = np.unique(df_label['cloneID'])\n",
    "            nb_clusters = len(oldcloneIDs)\n",
    "            # correct cloneID\n",
    "            oldcloneID2newcloneID = {oldcloneID:(start_cloneID+i) for i,oldcloneID in enumerate(oldcloneIDs)}\n",
    "            df.loc[df['clonelabel'] == label, 'cloneID'] = df.loc[df['clonelabel'] == label, 'cloneID'].apply(lambda x: oldcloneID2newcloneID[x])\n",
    "\n",
    "            for oldcloneID,cloneID in oldcloneID2newcloneID.items():\n",
    "                sample2cloneID2clonetype[sample][cloneID] = df_label[df_label['cloneID']==oldcloneID]['clonetype'].iloc[0]\n",
    "            start_cloneID += clonelabel2max_nb_cluster[label]\n",
    "        df.to_csv(os.path.join(pathsave,'sample2data/{0}.csv'.format(sample)), index=True)\n",
    "        \n",
    "    # saving clone infos\n",
    "    col_cloneID, col_label, col_cat = [], [], []\n",
    "    count = 0\n",
    "    for label in all_clonelabels:\n",
    "        for i in range(clonelabel2max_nb_cluster[label]):\n",
    "            col_cloneID.append(count)\n",
    "            col_label.append(label)\n",
    "            col_cat.append(label2category(label))\n",
    "            count += 1\n",
    "\n",
    "    dic_df = {'cloneID':col_cloneID, 'clonelabel':col_label, 'clonecategory':col_cat}\n",
    "    for id_sample, sample in enumerate(tqdm(sample_names)):\n",
    "        col_clonetype = []\n",
    "        for cloneID in col_cloneID:\n",
    "            col_clonetype.append(sample2cloneID2clonetype[sample].get(cloneID, None))\n",
    "        dic_df[\"clonetype_{0}\".format(sample)] = col_clonetype\n",
    "\n",
    "    df = pd.DataFrame(dic_df)\n",
    "    df = df.set_index('cloneID')\n",
    "    df.to_csv(pathsave+'clone_infos.csv'.format(sample), index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d183495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for clonemode in clonemodes[:1]:\n",
    "    for gene_set_collection in gene_set_collections[[4]]:\n",
    "        pathsave = '/data/users/04_share_reanalysis_results/melanoma_2025/02_atypical_removed_preprocessing/metacells_{0}_{1}_rawcounts/'.format(gene_set_collection, clonemode)\n",
    "        pathgsva = '/data/users/04_share_reanalysis_results/02_melanoma/04_metacells_gsva/{0}/'.format('gene' if ('gene' in gene_set_collection) else gene_set_collection)\n",
    "        import os\n",
    "        if not os.path.exists(pathsave):\n",
    "            os.makedirs(pathsave)\n",
    "        if not os.path.exists(os.path.join(pathsave, 'sample2data')):\n",
    "            os.makedirs(os.path.join(pathsave, 'sample2data'))\n",
    "        print('Clone mode:', clonemode)\n",
    "        print('Features:', gene_set_collection)\n",
    "        sample_names = get_sample_names(use_scatrex_clone=(clonemode=='scatrex'), gene_feature=('gene' in gene_set_collection))\n",
    "        preprocess_data(sample_names, gene_set_collection, use_scatrex_clone=(clonemode=='scatrex'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
