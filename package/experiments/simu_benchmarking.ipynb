{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b415218b",
   "metadata": {},
   "source": [
    "# scClone2DR Simulation Benchmark\n",
    "\n",
    "This notebook performs a comprehensive benchmark comparison of the scClone2DR model against several baseline methods using simulated data.\n",
    "\n",
    "## Overview\n",
    "\n",
    "The benchmark evaluates different approaches for predicting drug response from single-cell data:\n",
    "\n",
    "1. **scClone2DR** - The full single-cell clone to drug response model\n",
    "2. **Factorization Machine (FM)** - Matrix factorization approach\n",
    "3. **Neural Network (NN)** - Deep learning baseline\n",
    "4. **Dual Bulk** - Bimodal aggregation method\n",
    "5. **Bulk** - Simple bulk aggregation\n",
    "6. **Baseline** - Basic model without clone information\n",
    "\n",
    "## Workflow\n",
    "\n",
    "1. **Data Generation**: Create simulated training data with known ground truth\n",
    "2. **Train/Test Split**: Split data into training (50%) and testing (50%) sets\n",
    "3. **Model Training**: Train each model variant with appropriate regularization\n",
    "4. **Evaluation**: Compare models using:\n",
    "   - Drug effect prediction accuracy (L¹ error)\n",
    "   - Drug score predictions (MSE)\n",
    "   - Fold change correlations (explained variance)\n",
    "\n",
    "## Parameters\n",
    "\n",
    "- `setting`: Difficulty level (\"easy\", \"very_easy\", or \"hard\")\n",
    "- `n_steps`: Number of training steps (default: 2000)\n",
    "- Regularization: L1 and L2 penalties\n",
    "\n",
    "## Output\n",
    "\n",
    "The notebook generates comparison plots showing:\n",
    "- L¹ error curves for drug effect predictions\n",
    "- Violin plots of drug scores with MSE comparison\n",
    "- Scatter plots of predicted vs. true fold changes for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd24673a-5642-4510-8a6e-3c36b44ee57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import scClone2DR as sccdr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "n_steps = 2000\n",
    "np.float_ = np.float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9bd756-6463-4f12-bd23-f9ef27cff3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelscClone2DR = sccdr.models.scClone2DR()\n",
    "\n",
    "setting = \"easy\"\n",
    "if setting==\"easy\":\n",
    "    R = 20\n",
    "    neg_bin = 100\n",
    "elif setting==\"very_veasy\":\n",
    "    R = 30\n",
    "    neg_bin = 10000\n",
    "else:\n",
    "    R = 5\n",
    "    neg_bin = 2\n",
    "data_ref = modelscClone2DR.get_simulated_training_data({'C':24,'R':R,'N':100,'Kmax':7, 'D':30, 'theta_rna':15}, neg_bin_n=neg_bin, mode_nu=\"noise_correction\", mode_theta=\"not shared decoupled\")\n",
    "data_ref['pi'] = modelscClone2DR.compute_survival_probas_subclone_features(data_ref, data_ref)\n",
    "idxs_train = [i for i in range(int(0.5*data_ref['N']))]\n",
    "idxs_test = [i for i in range(int(0.5*data_ref['N']), data_ref['N'])]\n",
    "\n",
    "data_train, data_test = modelscClone2DR.get_data_split_simu(data_ref, idxs_train, idxs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c700cd-b4d2-4da3-981f-683021974225",
   "metadata": {},
   "outputs": [],
   "source": [
    "if setting not in [\"easy\", \"very_easy\"]:\n",
    "    params_svi = modelscClone2DR.train(data_train, penalty_l1=0.1, penalty_l2=0.1 , n_steps=n_steps)\n",
    "else:\n",
    "    params_svi = modelscClone2DR.train(data_train, penalty_l1=0.02, penalty_l2=0.02 , n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf56940-09d4-43fe-a782-c756218b2b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svi = modelscClone2DR.convert_to_tensor(params_svi)\n",
    "params_svi['pi'] = modelscClone2DR.compute_survival_probas_subclone_features(data_ref, params_svi)\n",
    "modelscClone2DR.compute_all_stats(data_ref, data_ref, params_svi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd6769f-923a-40e2-a4f7-79eeac321983",
   "metadata": {},
   "source": [
    "# Bulk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921e7b33-e355-4ae7-89cd-52c42c3c04dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bulk = sccdr.models.scClone2DR()\n",
    "databulk = model_bulk.get_bulk_from_data(data_ref)\n",
    "data_train_bulk = model_bulk.get_bulk_from_data(data_train)\n",
    "data_test_bulk = model_bulk.get_bulk_from_data(data_test)\n",
    "if setting not in [\"easy\", \"very_easy\"]:\n",
    "    params_svi_bulk = model_bulk.train(data_train_bulk, penalty_l1=0.1, penalty_l2=0.1 , n_steps=n_steps)\n",
    "else:\n",
    "    params_svi_bulk = model_bulk.train(data_train_bulk, penalty_l1=0.02, penalty_l2=0.02 , n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288972e1-87ba-41bb-8c83-a484c79117e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bulk.compute_all_stats4bulk_or_bimodal(modelscClone2DR, data_ref, databulk, params_svi_bulk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6e1e1-264b-4c88-9819-1c9c136a8569",
   "metadata": {},
   "source": [
    "# Bimodal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88620e01-b2b8-40e8-86b3-26fe7028d1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bimodal = sccdr.models.scClone2DR()\n",
    "databimodal = model_bimodal.get_bimodal_from_data(data_ref)\n",
    "data_train_bimodal = model_bimodal.get_bimodal_from_data(data_train)\n",
    "data_test_bimodal = model_bimodal.get_bimodal_from_data(data_test)\n",
    "\n",
    "if setting not in [\"easy\", \"very_easy\"]:\n",
    "    params_svi_bimodal = model_bimodal.train(data_train_bimodal, penalty_l1=0.1, penalty_l2=0.1 , n_steps=n_steps)\n",
    "else:\n",
    "    params_svi_bimodal = model_bimodal.train(data_train_bimodal, penalty_l1=0.02, penalty_l2=0.02 , n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab05f2c-b695-4402-bddb-7aeef3dc2e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bimodal.compute_all_stats4bulk_or_bimodal(modelscClone2DR, data_ref, databimodal, params_svi_bimodal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f48d5d-c12b-4015-b832-658ff39bcea1",
   "metadata": {},
   "source": [
    "# Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feac4f68-4a5e-4583-abb5-9dde0cc7f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = sccdr.models.scClone2DR()\n",
    "database = model_base.get_base_from_data(data_ref)\n",
    "data_train_base = model_base.get_base_from_data(data_train)\n",
    "data_test_base = model_base.get_base_from_data(data_test)\n",
    "\n",
    "if setting not in [\"easy\", \"very_easy\"]:\n",
    "    params_svi_base = model_base.train(data_train_base, penalty_l1=0.1, penalty_l2=0.1 , n_steps=n_steps)\n",
    "else:\n",
    "    params_svi_base = model_base.train(data_train_base, penalty_l1=0.02, penalty_l2=0.02 , n_steps=n_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351ac8b3-42b3-4837-82a0-d86e1f61dcc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_svi_base = model_base.convert_to_tensor(params_svi_base)\n",
    "params_svi_base['pi'] = model_base.compute_survival_probas_subclone_features(database, params_svi_base)\n",
    "model_base.compute_all_stats(data_ref, data_ref, params_svi_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83cce05-5057-4b47-87ab-05ce67e22623",
   "metadata": {},
   "source": [
    "# Factorization machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1273c388-eb4b-405f-8471-0c28a72c11c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmax, N, latent_dim = data_train['X'].shape\n",
    "N = data_train['n_r'].shape[2]\n",
    "D = data_train['D']\n",
    "modelFM = sccdr.models.FM(modelscClone2DR.cluster2clonelabel, modelscClone2DR.clonelabel2cat)\n",
    "modelFM.train(data_train)\n",
    "modelFM.eval(data_ref, true_params = {'pi': data_ref['pi']})\n",
    "\n",
    "modelFM_trueprops = sccdr.models.FM(modelscClone2DR.cluster2clonelabel, modelscClone2DR.clonelabel2cat, use_true_proportions=True)\n",
    "modelFM_trueprops.train(data_train)\n",
    "modelFM_trueprops.eval(data_ref, true_params = {'pi': data_ref['pi']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc5dfd70-4a67-4951-a60a-8c249f810c49",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adbc021-730d-4a86-a410-f91d0c5b4dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Kmax, N, latent_dim = data_train['X'].shape\n",
    "N = data_train['n_r'].shape[2]\n",
    "D = data_train['D']\n",
    "modelNN = sccdr.models.NN(modelscClone2DR.cluster2clonelabel, modelscClone2DR.clonelabel2cat)\n",
    "modelNN.train(data_train, data_ref['beta'])\n",
    "modelNN.eval(data_ref, true_params = {'pi': data_ref['pi'], 'beta':data_ref['beta']})\n",
    "\n",
    "modelNN_trueprops = sccdr.models.NN(modelscClone2DR.cluster2clonelabel, modelscClone2DR.clonelabel2cat, use_true_proportions=True)\n",
    "modelNN_trueprops.train(data_train, data_ref['beta'])\n",
    "modelNN_trueprops.eval(data_ref, true_params = {'pi': data_ref['pi'], 'beta':data_ref['beta']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0bff69-6fc9-41b4-ad2e-eeaa6ceb5684",
   "metadata": {},
   "source": [
    "# Visualizing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7217d9d-21ef-4cd7-8e33-9aaf5bd31f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "res['us'] = modelscClone2DR.results\n",
    "res['base'] = model_base.results\n",
    "res['bulk'] = model_bulk.results\n",
    "res['bimodal'] = model_bimodal.results\n",
    "res['fm'] = modelFM.results\n",
    "res['nn'] = modelNN.results\n",
    "import seaborn as sns\n",
    "colors_models = sns.color_palette('Set2')\n",
    "\n",
    "models = ['us','fm','nn','bimodal','bulk', 'base']\n",
    "model2name = {'us':'scClone2DR', 'base':'Baseline', 'bimodal':'Dual bulk','bulk':'Bulk','fm':'FM','nn':'NN', \n",
    "              'fm_true_props': 'FM true props','nn_true_props':'NN true props'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a792379-3e31-4dd5-859c-cb148a617ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in models:\n",
    "    x = np.abs(1.-res[m]['true_drug_effects'].numpy())\n",
    "    argidxs = np.argsort(x)\n",
    "    argidxs_dec = np.flip(argidxs, axis=0)\n",
    "    x = x[argidxs_dec]\n",
    "    err = np.cumsum(np.abs(res[m]['true_drug_effects'].numpy()-res[m]['drug_effects'].numpy())[argidxs_dec])/np.cumsum(np.ones(len(x)))\n",
    "    plt.plot(x, (err), label=model2name[m])\n",
    "plt.legend(loc=2)\n",
    "plt.ylabel('$L^1$ error on the drug effects', fontsize=14)\n",
    "plt.xlabel('Threshold', fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81033536",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib import collections\n",
    "\n",
    "# Initialize the dictionary\n",
    "dic = {'method': [], \"drug scores\": [], \"statistic\": [], 'ground_truth':[]}\n",
    "mses = {}\n",
    "\n",
    "# Loop through models and calculate MSE\n",
    "for m in models:\n",
    "    estimated_scores = np.array(res[m]['drug_scores'])\n",
    "    true_scores = np.array(res[m]['true_drug_scores'])\n",
    "    \n",
    "    # Calculate MSE\n",
    "    mse = np.mean((estimated_scores - true_scores) ** 2)\n",
    "    mses[model2name[m]] = mse\n",
    "    \n",
    "    # Populate dictionary\n",
    "    dic['method'] += [model2name[m] for i in range(2 * len(estimated_scores))]\n",
    "    dic['drug scores'] += list(estimated_scores)\n",
    "    dic['drug scores'] += list(true_scores)\n",
    "    dic['ground_truth'] += [False for i in range(len(estimated_scores))]\n",
    "    dic['ground_truth'] += [True for i in range(len(true_scores))]\n",
    "    dic['statistic'] += ['estimated ' for i in range(len(estimated_scores))]\n",
    "    dic['statistic'] += ['ground truth' for i in range(len(true_scores))]\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(dic)\n",
    "\n",
    "# Set theme and style\n",
    "sns.set_theme(style='white')\n",
    "sns.set_style(\"ticks\", {\"xtick.major.size\": 12, \"ytick.major.size\": 12})\n",
    "\n",
    "# Create figure with two subplots\n",
    "fig, (ax_violin, ax_bar) = plt.subplots(nrows=2, ncols=1, figsize=(10, 8), gridspec_kw={'height_ratios': [3, 1]})\n",
    "\n",
    "# Violin plot on top\n",
    "colors = {m:colors_models[i] for i,m in enumerate((models))}\n",
    "models = ['us','fm','nn','bimodal','bulk', 'base']\n",
    "colors = {}\n",
    "colors['us'] = \"#009E73\"\n",
    "colors['fm'] = \"#0072B2\"\n",
    "colors['nn'] = \"#56B4E9\"\n",
    "colors['bimodal'] = \"#D55E00\"\n",
    "colors['bulk'] = \"#E69F00\"\n",
    "colors['base'] = \"#F0E442\"\n",
    "\n",
    "\n",
    "ax = sns.violinplot(data=df, x=\"method\", y=\"drug scores\", hue=\"statistic\", split=True, inner=\"quart\", density_norm=\"width\", legend = False, ax=ax_violin)\n",
    "for ind, violin in enumerate(ax.findobj(collections.PolyCollection)):\n",
    "    rgb = colors[models[ind//2]]\n",
    "    if ind % 2 != 0:\n",
    "        rgb = \"gray\"  # make white\n",
    "    violin.set_facecolor(rgb)\n",
    "ax_violin.plot([],[], linewidth=10, c=\"gray\", label='Ground truth')\n",
    "ax_violin.legend(fontsize=15)\n",
    "ax_violin.set_ylabel('Drug Scores', fontsize=19)\n",
    "ax_violin.set_xlabel('')\n",
    "ax_violin.legend(loc=1, fontsize=19,ncol=2)\n",
    "ax_violin.tick_params(axis='x', rotation=40)\n",
    "ax_violin.set_xticks([])  # Remove the x-ticks\n",
    "ax_violin.set_xticklabels([])  # Remove the x-tick labels\n",
    "\n",
    "# MSE bar plot on the bottom\n",
    "methods = list(mses.keys())\n",
    "mse_values = list(mses.values())\n",
    "ax_bar.bar(methods, mse_values, color=[colors[mod] for mod in (models)])\n",
    "ax_bar.set_ylabel('MSE', fontsize=19)\n",
    "#ax_bar.set_xlabel('Method', fontsize=18)\n",
    "ax_bar.tick_params(axis='x', rotation=30, labelsize=19)\n",
    "\n",
    "# Align the x-ticks and make sure both plots share the same x-axis\n",
    "ax_bar.set_xticks(range(len(methods)))\n",
    "ax_bar.set_xticklabels(methods)\n",
    "\n",
    "# Save and show plot\n",
    "plt.tight_layout()\n",
    "ax_violin.text(-1.25,1.45, \"(b)\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a1211-0e1d-417d-9a5b-b45956e4d991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from sklearn.metrics import explained_variance_score\n",
    "\n",
    "\n",
    "size_dots = 2\n",
    "\n",
    "custom_font_size = 20\n",
    "custom_fontsize_labelsaxis = 16\n",
    "fontsizelegend = 18\n",
    "tit = ['scClone2DR', 'FM', 'NN', 'Dual bulk', 'Bulk', 'Baseline',  'FM model (true props)', 'NN model (true props)']\n",
    "\n",
    "# Create subplots\n",
    "fig = plt.figure(figsize=(12, 8))\n",
    "gs = GridSpec(2, 3, width_ratios=[1, 1, 1])\n",
    "\n",
    "# Plot for model 1\n",
    "ax00 = fig.add_subplot(gs[0, 0])\n",
    "fc_true = res['us']['fold_change_true']\n",
    "fc_pred = res['us']['fold_change_pred']\n",
    "corr = np.round(np.corrcoef(fc_true, fc_pred)[0,1]**2, 3)\n",
    "rsquare = np.round(explained_variance_score(fc_true, fc_pred), 3)\n",
    "ax00.scatter(fc_true, fc_pred, label='{0}'.format(np.round(corr,3)), s=size_dots, c=colors['us'])\n",
    "ax00.set_title('{0}'.format(tit[0]), fontsize=custom_font_size)\n",
    "ax00.set_xlabel('Fold change (ground truth)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax00.set_ylabel('Fold change (predicted)', fontsize=custom_fontsize_labelsaxis)\n",
    "m = min([np.min(fc_pred),np.min(fc_true)])\n",
    "ax00.set_ylim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax00.text(m+0.02,m+0.02, \"Explained variance: {0}\".format(corr,rsquare), fontsize=14)\n",
    "\n",
    "\n",
    "# Plot for model 2\n",
    "ax01 = fig.add_subplot(gs[0, 1])\n",
    "fc_true = res['us']['fold_change_true']\n",
    "fc_pred = res['fm']['fold_change_pred']\n",
    "corr = np.round(np.corrcoef(fc_true, fc_pred)[0,1]**2, 3)\n",
    "rsquare = np.round(explained_variance_score(fc_true, fc_pred), 3)\n",
    "ax01.scatter(fc_true, fc_pred, label='{0}'.format(np.round(corr,3)), s=size_dots, c=colors['fm'])\n",
    "ax01.set_title('{0}'.format(tit[1]), fontsize=custom_font_size)\n",
    "ax01.set_xlabel('Fold change (ground truth)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax01.set_ylabel('Fold change (predicted)', fontsize=custom_fontsize_labelsaxis)\n",
    "m = min([np.min(fc_pred),np.min(fc_true)])\n",
    "ax01.set_ylim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax01.set_xlim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax01.text(m+0.02,m+0.02, \"Explained variance: {0}\".format(corr,rsquare), fontsize=14)\n",
    "\n",
    "# Plot for model 3\n",
    "ax10 = fig.add_subplot(gs[0, 2])\n",
    "fc_true = res['us']['fold_change_true']\n",
    "fc_pred = res['nn']['fold_change_pred']\n",
    "corr = np.round(np.corrcoef(fc_true, fc_pred)[0,1]**2, 3)\n",
    "rsquare = np.round(explained_variance_score(fc_true, fc_pred), 3)\n",
    "ax10.scatter(fc_true, fc_pred, label='{0}'.format(np.round(corr,3)), s=size_dots, c=colors['nn'])\n",
    "ax10.set_title('{0}'.format(tit[2]), fontsize=custom_font_size)\n",
    "ax10.set_xlabel('Fold change (ground truth)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax10.set_ylabel('Fold change (predicted)', fontsize=custom_fontsize_labelsaxis)\n",
    "m = min([np.min(fc_pred),np.min(fc_true)])\n",
    "ax10.set_ylim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax10.set_xlim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax10.text(m+0.02,m+0.02, \"Explained variance: {0}\".format(corr,rsquare), fontsize=14)\n",
    "\n",
    "# Plot for model 4\n",
    "ax11 = fig.add_subplot(gs[1, 0])\n",
    "fc_true = res['us']['fold_change_true']\n",
    "fc_pred = res['bimodal']['fold_change_pred']\n",
    "corr = np.round(np.corrcoef(fc_true, fc_pred)[0,1]**2, 3)\n",
    "rsquare = np.round(explained_variance_score(fc_true, fc_pred), 3)\n",
    "ax11.scatter(fc_true, fc_pred, label='{0}'.format(np.round(corr,3)), s=size_dots, c=colors['bimodal'])\n",
    "ax11.set_title('{0}'.format(tit[3]), fontsize=custom_font_size)\n",
    "ax11.set_xlabel('Fold change (ground truth)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax11.set_ylabel('Fold change (predicted)', fontsize=custom_fontsize_labelsaxis)\n",
    "m = min([np.min(fc_pred),np.min(fc_true)])\n",
    "ax11.set_ylim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax11.set_xlim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax11.text(m+0.02,m+0.02, \"Explained variance: {0}\".format(corr,rsquare), fontsize=14)\n",
    "\n",
    "\n",
    "# Plot for model 5\n",
    "ax12 = fig.add_subplot(gs[1, 1])\n",
    "fc_true = res['us']['fold_change_true']\n",
    "fc_pred = res['bulk']['fold_change_pred']\n",
    "corr = np.round(np.corrcoef(fc_true, fc_pred)[0,1]**2, 3)\n",
    "rsquare = np.round(explained_variance_score(fc_true, fc_pred), 3)\n",
    "ax12.scatter(fc_true, fc_pred, label='{0}'.format(np.round(corr,3)), s=size_dots, c=colors['bulk'])\n",
    "ax12.set_title('{0}'.format(tit[4]), fontsize=custom_font_size)\n",
    "ax12.set_xlabel('Fold change (ground truth)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax12.set_ylabel('Fold change (predicted)', fontsize=custom_fontsize_labelsaxis)\n",
    "m = min([np.min(fc_pred),np.min(fc_true)])\n",
    "ax12.set_ylim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax12.set_xlim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax12.text(m+0.02,m+0.02, \"Explained variance: {0}\".format(corr,rsquare), fontsize=14)\n",
    "\n",
    "# Plot for model 6\n",
    "ax02 = fig.add_subplot(gs[1, 2])\n",
    "fc_true = res['us']['fold_change_true']\n",
    "fc_pred = res['base']['fold_change_pred']\n",
    "corr = np.round(np.corrcoef(fc_true, fc_pred)[0,1]**2, 3)\n",
    "rsquare = np.round(explained_variance_score(fc_true, fc_pred), 3)\n",
    "ax02.scatter(fc_true, fc_pred, label='{0}'.format(np.round(corr,3)), s=size_dots, c=colors['base'])\n",
    "ax02.set_title('{0}'.format(tit[5]), fontsize=custom_font_size)\n",
    "m = min([np.min(fc_pred),np.min(fc_true)])\n",
    "ax02.set_xlabel('Fold change (ground truth)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax02.set_ylabel('Fold change (predicted)', fontsize=custom_fontsize_labelsaxis)\n",
    "ax02.set_ylim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax02.set_xlim(min([np.min(fc_pred),np.min(fc_true)]), max([np.max(fc_pred),np.max(fc_true)]))\n",
    "ax02.text(m+0.02,m+0.02, \"Explained variance: {0}\".format(corr,rsquare), fontsize=14)\n",
    "\n",
    "# Create a colorbar\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "\n",
    "ax00.text(-0.3,0.083, \"(a)\", fontsize=20)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
